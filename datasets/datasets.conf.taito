[coco]
dataset_class = CocoDataset
root_dir = /proj/mediaind/picsom/databases/COCO
features_path = features/

[coco:train2014]
image_dir = image_captioning/train2014_256x256
caption_path = download/annotations/captions_train2014.json

[coco:val2014]
image_dir = image_captioning/val2014_256x256
caption_path = download/annotations/captions_val2014.json

[coco:train2014:no_resize]
image_dir = download/images/train2014

[coco:val2014:no_resize]
image_dir = download/images/val2014

[coco:train2017]
caption_path = download/annotations/captions_train2017.json
image_dir = image_captioning/train2014_256x256

[coco:val2017]
caption_path = download/annotations/captions_val2017.json
image_dir = image_captioning/val2014_256x256

[vgim2p]
# Visual Genome paragraph captions
dataset_class = VisualGenomeIM2PDataset
root_dir = /proj/mediaind/picsom/databases/visualgenome
image_dir = image_captioning/images_256x256
caption_path = download/im2p/paragraphs_v1.json
# We use COCO vocab for pre-training compatibility:
features_path = features

[vgim2p:no_resize]
image_dir = download/1.2/VG/1.2/images

[vgim2p:train]
subset = /proj/mediaind/picsom/databases/visualgenome/download/im2p/train_split.json

[vgim2p:val]
subset = /proj/mediaind/picsom/databases/visualgenome/download/im2p/val_split.json

[vgim2p:test]
subset = /proj/mediaind/picsom/databases/visualgenome/download/im2p/test_split.json

[vgregions]
# Visual Genome region descriptions
dataset_class = VisualGenomeRegionsDataset
root_dir = /proj/mediaind/picsom/databases/visualgenome
image_dir = download/1.2/VG/1.2/images 
# Currently using *.feather file to load regions data, as it is much faster to filter and split:
#caption_path = download/1.2/VG/1.2/region_descriptions.json
caption_path = download/1.2/VG/1.2/region_descriptions.feather
features_path = features

[vgregions:no_resize]
image_dir = download/1.2/VG/1.2/images

[vgregions:train]
subset = download/densecap_splits.json:train

[vgregions:val]
subset = download/densecap_splits.json:val

[vgregions:test]
subset = download/densecap_splits.json:test

[msrvtt]
dataset_class = MSRVTTDataset
root_dir = /proj/mediaind/picsom/databases/MSR-VTT
image_dir = middleframes/resized/
caption_path = download/train_val_videodatainfo.json
features_path = features/

[msrvtt:train]
subset = train

[msrvtt:validate]
# MSR-VTT validation set
subset = validate

[trecvid2018]
dataset_class = TRECVID2018Dataset
root_dir = /proj/mediaind/picsom/databases/trecvid2018
image_dir = middleframes/
features_path = features/

[trecvid2016]

[picsom]
dataset_class = PicSOMDataset
picsom_root   = /proj/mediaind/picsom
features_path = features
image_dir     =

[picsom:COCO]
root_dir      = /proj/mediaind/picsom/databases/COCO
caption_path  = textdumps/gt-cooked.txt

[picsom:COCO:train2014]
subset        = train2014

[picsom:COCO:val2014]
subset        = val2014

[picsom:trecvid2018]
root_dir      = /proj/mediaind/picsom/databases/trecvid2018
features_path = features
caption_path  = textdumps/gt-cooked.txt
label_map     = label-map.txt
image_dir     =

[picsom:trecvid2018:test18g]
subset        = test18g

[picsom:trecvid2018:test17g]
subset        = test17g

[picsom:trecvid2018:test16g]
subset        = test16g

[picsom:trecvid2018:testall]
subset        = testall

[picsom:tgif]
root_dir      = /proj/mediaind/picsom/databases/tgif
features_path = features
caption_path  = textdumps/gt-cooked.txt
label_map     = label-map.txt
image_dir     =

[picsom:tgif:imageset]
subset        = imageset
